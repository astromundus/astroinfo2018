{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### ASTROINFORMATICS, Fall 2018\n",
    "https://github.com/astromundus/astroinfo2018/blob/master/lectures-notebooks/Week-2-1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 2  Introduction to Probability & Statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Resources for this notebook include:\n",
    "\n",
    "- [Textbook](http://press.princeton.edu/titles/10159.html) Chapters [3](chap3.pdf) and 4.  \n",
    "- [Gordon Richard's notebooks](https://github.com/gtrichards/PHYS_T480)\n",
    "- random contributions from a large number of colleagues (e.g. Jake VanderPlas, Andy Connolly)\n",
    "\n",
    "##### Suggested supplemental background reading:\n",
    "\n",
    "[David Hogg: \"Data analysis recipes: Probability calculus for inference\"](https://arxiv.org/abs/1205.4446)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Learning goals for Week 2 (mostly based on Chapter 3 material): \n",
    "\n",
    "- Probability Rules (notation, definitions, conditional probability, Bayes Rule).\n",
    "- How do I robustly estimate location and scale parameters of a one-dimensional data set?  \n",
    "- Statistical distributions and how do we describe them? \n",
    "- Estimators, location and scale, sample vs. population, bias and scatter.\n",
    "\n",
    "\n",
    "- How do I use python to generate various statistical distributions, such as Cauchy, Laplace, etc.  \n",
    "- The Central Limit Theorem. \n",
    "- Robust estimators. \n",
    "- How do I robustly estimate parameters of a two-dimensional Gaussian?  \n",
    "- Bivariate and Multivariate Distribution Functions.  \n",
    "- How do we make a histogram and why? How do we choose optimal bin width?\n",
    "  Do histogram bins need to be same size?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Notation\n",
    "\n",
    "### Variables\n",
    "\n",
    "First we need to go over some of the notation that the book uses.   \n",
    "\n",
    "$x$ is a scalar quantity, measured $N$ times\n",
    "\n",
    "$x_i$ is a single measurement with $i=1,...,N$\n",
    "\n",
    "$\\{x_i\\}$ refers to the set of all N measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Population vs Empirical PDF\n",
    "\n",
    "We are generally trying to *estimate* $h(x)$, the *true* distribution from which the values of $x$ are drawn. We will refer to $h(x)$ as the probability density (distribution) function or the \"pdf\" and $h(x)dx$ is the propobability of a value lying between $x$ and $x+dx$. \n",
    "\n",
    "While $h(x)$ is the \"true\" pdf (or **population** pdf).  What we *measure* from the data is the **empirical** pdf, which is denoted $f(x)$.  So, $f(x)$ is a *model* of $h(x)$.  In principle, with infinite data $f(x) \\rightarrow h(x)$, but in reality measurement errors keep this from being strictly true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parametric vs. Non-parametric\n",
    "\n",
    "If we are attempting to guess a *model* for $h(x)$, then the process is *parametric*.  With a model solution we can generate new data that should mimic what we measure.\n",
    "\n",
    "If we are not attempting to guess a model, then the process is *nonparametic*.  That is we are just trying to describe the data that we see in the most compact manner that we can, but we are not trying to produce mock data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probability\n",
    "\n",
    "The probability of $A$, $p(A)$, is the probability that some event will happen (say a coin toss), or if the process is continuous, the probability of $A$ falling in a certain range.  (N.B., Technically these two things are different and sometimes are indicated by $P$ and $p$, but we'll ignore that here).\n",
    "\n",
    "$p(A)$ must be positive definite for all $A$ and the sum/integral of the pdf must be unity.\n",
    "\n",
    "If we have two events, $A$ and $B$, the possible combinations are illustrated by the following figure:\n",
    "![Figure 3.1](http://www.astroml.org/_images/fig_prob_sum_1.png)\n",
    "\n",
    "$A \\cup B$ is the *union* of sets $A$ and $B$.\n",
    "\n",
    "$A \\cap B$ is the *intersection* of sets $A$ and $B$.\n",
    "\n",
    "The probability that *either* $A$ or $B$ will happen (which could include both) is the *union*, given by\n",
    "\n",
    "$$p(A \\cup B) = p(A) + p(B) - p(A \\cap B)$$\n",
    "\n",
    "The figure makes it clear why the last term is necessary.  Since $A$ and $B$ overlap, we are double-counting the region where *both* $A$ and $B$ happen, so we have to subtract this out.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability that *both* $A$ and $B$ will happen, $p(A \\cap B)$, is \n",
    "\n",
    "$$p(A \\cap B) = p(A|B)p(B) = p(B|A)p(A)$$\n",
    "\n",
    "where p(A|B) is the probability of A *given that* B is true and is called the *conditional probability*.  So the $|$ is short for \"given that\".\n",
    "\n",
    "In other words: *\"The probability that both A and B have occured is equal to the probability B has occured times the probability that A will occur if B occured\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If events B_i are disjoint and their union is the set of all possible outcomes, then the **law of total probability** says that:\n",
    "\n",
    "$$p(A) = \\sum_ip(A|B_i)p(B_i)$$\n",
    "\n",
    "Example:\n",
    "\n",
    "    A = hit head on door frame, B = { is tall, is average, is short }\n",
    "    P(A) = P(A|is tall) + P(B|is average) + P(C|is short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "N.B.  Just to be annoying, different people use different notation and the following all mean the same thing\n",
    "\n",
    "$$p(A \\cap B) = p(A,B) = p(AB) = p(A \\,{\\rm and}\\, B)$$\n",
    "\n",
    "We will use the comma notation as in the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is important to realize that the following is *always* true\n",
    "$$p(A,B) = p(A|B)p(B) = p(B|A)p(A)$$\n",
    "\n",
    "However, if $A$ and $B$ are ***independent***, then \n",
    "\n",
    "$$p(A,B) = p(A)p(B)$$\n",
    "\n",
    "Example:\n",
    "\n",
    "     John is successful and John is a Libra.\n",
    "     \n",
    "In other words, ***knowing A happened tells us nothing about whether B happened (or will happen), and vice versa***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at another example.\n",
    "\n",
    "If you have a bag with 5 marbles, 3 yellow and 2 blue and you want to know the probability of picking 2 yellow marbles in a row, that would be\n",
    "\n",
    "$$p(Y_1,Y_2) = p(Y_1)p(Y_2|Y_1).$$\n",
    "\n",
    "$p(Y_1) = \\frac{3}{5}$ since you have an equally likely chance of drawing any of the 5 marbles.\n",
    "\n",
    "If you did not put the first marble back in the back after drawing it (sampling *without* \"replacement\"), then the probability\n",
    "$p(Y_2|Y_1) = \\frac{2}{4}$, so that\n",
    "$$p(Y_1,Y_2) = \\frac{3}{5}\\frac{2}{4} = \\frac{3}{10}.$$\n",
    "\n",
    "But if you put the first marble back, then\n",
    "$p(Y_2|Y_1) = \\frac{3}{5} = p(Y_2)$, so that \n",
    "$$p(Y_1,Y_2) = \\frac{3}{5}\\frac{3}{5} = \\frac{9}{25}.$$\n",
    "\n",
    "In the first case $A$ and $B$ (or rather $Y_1$ and $Y_2$) are *not* independent, whereas in the second case they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is a more complicated example from \n",
    "[Jo Bovy's class at UToronto](http://astro.utoronto.ca/%7Ebovy/teaching.html)\n",
    "![Bovy_L1-StatMiniCourse_page21](figures/Bovy_L1-StatMiniCourse_page21.png)\n",
    "\n",
    "As illustrated, \n",
    "$$p(A \\,{\\rm or}\\, B|C) = p(A|C) + p(B|C) - p(A \\, {\\rm and}\\, B|C)$$ \n",
    "\n",
    "This illustration also explains why $$p(x|y)p(y) = p(y|x)p(x)$$ (used below),\n",
    "or in the notation of this figure: $$p(A \\, {\\rm and}\\, B) \\equiv p(A,B) = p(A|B)p(B) = p(B|A)p(A)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Need more help with this?  Try watching some Khan Academy videos and working through the exercises:\n",
    "[https://www.khanacademy.org/math/probability/probability-geometry](https://www.khanacademy.org/math/probability/probability-geometry)\n",
    "\n",
    "[https://www.khanacademy.org/math/precalculus/prob-comb](https://www.khanacademy.org/math/precalculus/prob-comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes' Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We've seen that the probability of $x$ and $y$ occurring can be written as:\n",
    "\n",
    "$$p(x,y) = p(x|y)p(y) = p(y|x)p(x)$$\n",
    "\n",
    ". We can define the ***marginal probability*** as\n",
    "\n",
    "$$p(x) = \\int p(x,y)dy,$$\n",
    "\n",
    "where marginal means the probability of $x$ occurring irrespective what $y$ is. This is essentially projecting on to one axis (integrating over the other axis, see the figure in the Notebook, below).\n",
    "\n",
    "Given these two, we can write:\n",
    "\n",
    "$$p(x) = \\int p(x|y)p(y) dy$$\n",
    "\n",
    "This is just the law of total probability, but for continous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Marginal and contitional probability distributions\n",
    "\n",
    "In the following figure, we have a 2-D distribution in $x-y$ parameter space.  Here $x$ and $y$ are *not* independent as, once you pick a $y$, your values of $x$ are constrained.\n",
    "\n",
    "The *marginal* distributions are shown on the left and bottom sides of the left panel.  As the equation above says, this is just the integral along the $x$ direction for a given $y$ (left side panel) or the integral along the $y$ direction for a given $x$ (bottom panel).  \n",
    "\n",
    "The three panels on the right show the *conditional* probability (of $x$) for three $y$ values: $$p(x|y=y_0)$$  These are just \"slices\" through the 2-D distribution.\n",
    "\n",
    "![http://www.astroml.org/_images/fig_conditional_probability_1.png](http://www.astroml.org/_images/fig_conditional_probability_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then, again starting with:\n",
    "\n",
    "$$p(x|y)p(y) = p(y|x)p(x)$$\n",
    "\n",
    "we can write:\n",
    "\n",
    "$$p(y|x) = \\frac{p(x|y)p(y)}{p(x)} = \\frac{p(x|y)p(y)}{\\int p(x|y)p(y) dy}$$\n",
    "\n",
    "which in words says that\n",
    "\n",
    "> the (conditional) probability of $y$ given $x$ is just the (conditional) probability of $x$ given $y$ times the (marginal) probability of $y$ divided by the (marginal) probability of $x$, where the latter is just the integral of the numerator.\n",
    "\n",
    "This is **Bayes' rule**, which itself is not at all controversial, though its application can be as we'll discuss later (Week 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Lego's \n",
    "\n",
    "An example with Lego's (it's awesome):\n",
    "[https://www.countbayesie.com/blog/2015/2/18/bayes-theorem-with-lego](https://www.countbayesie.com/blog/2015/2/18/bayes-theorem-with-lego)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Monty Hall Problem\n",
    "\n",
    "You are playing a game show and are shown 2 doors.  One has a car behind it, the other a goat.  What are your chances of picking the door with the car?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "OK, now there are 3 doors: one with a car, two with goats.  The game show host asks you to pick a door, but not to open it yet.  Then the host opens one of the other two doors (that you did not pick), making sure to select one with a goat.  The host offers you the opportunity to switch doors.  Do you?\n",
    " \n",
    " \n",
    "![https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Monty_open_door.svg/180px-Monty_open_door.svg.png](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Monty_open_door.svg/180px-Monty_open_door.svg.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now you are back at the 2 door situation.  But what can you make of your prior information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$p(1{\\rm st \\; choice}) = 1/3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Try it:\n",
    "https://betterexplained.com/articles/understanding-the-monty-hall-problem/\n",
    "\n",
    "$p({\\rm other}) = 2/3$\n",
    "which doesn't change after host opens door without the prize.\n",
    "So, switching doubles your chances.  But only because you had prior information.  If someone walked in after the \"bad\" door was opened, then their probability of winning is the expected $1/2$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "![TextbookGrab1](figures/grab1.jpg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For $N$ choices, revealing $N-2$ \"answers\" doesn't change the probability of your choice.  It is still $\\frac{1}{N}$.  But it *does* change the probability of your knowledge of the *other* remaining choice by $N-1$ and it is $\\frac{N-1}{N}$. Therefore, by switching, you increase your chance of winning by a factor of (N-1). \n",
    "\n",
    "In the 3-door example, you double your chance of winning (from 1/3 to 2/3). \n",
    "\n",
    "This is an example of the use of *conditional* probability, where we have $p(A|B) \\ne p(A)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Contingency Table\n",
    "\n",
    "We can also use Bayes' rule to learn something about false positives and false negatives.\n",
    "\n",
    "Let's say that we have a test for a disease.  The test can be positive ($T=1$) or negative ($T=0$) and one can either have the disease ($D=1$) or not ($D=0$).  So, there are 4 possible combinations:\n",
    "$$T=0; D=0 \\;\\;\\;  {\\rm true \\; negative}$$\n",
    "$$T=0; D=1 \\;\\;\\; {\\rm false \\; negative}$$\n",
    "$$T=1; D=0 \\;\\;\\; {\\rm false \\; positive}$$\n",
    "$$T=1; D=1 \\;\\;\\; {\\rm true \\; positive}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "All else being equal, you have a 50% chance of being misdiagnosed.  Not good!  But the probability of disease and the accuracy of the test presumably are not random.\n",
    "\n",
    "If the rates of false positive and false negative are:\n",
    "$$p(T=1|D=0) = \\epsilon_{\\rm FP}$$\n",
    "$$p(T=0|D=1) = \\epsilon_{\\rm FN}$$\n",
    "\n",
    "then the true positive and true negative rates are just:\n",
    "$$p(T=0| D=0) = 1-\\epsilon_{\\rm FP}$$\n",
    "$$p(T=1| D=1) = 1-\\epsilon_{\\rm FN}$$\n",
    "\n",
    "Let's assume that $\\epsilon_{\\rm FP}=0.02$ and $\\epsilon_{\\rm FN}=0.001$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In graphical form this 2x2 p(T=0 or 1|D=0 or 1) matrix is:\n",
    "![http://www.astroml.org/_images/fig_contingency_table_1.png](http://www.astroml.org/_images/fig_contingency_table_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we have a **prior** regarding how likely the disease is, we can take this into account.\n",
    "\n",
    "$$p(D=1)=\\epsilon_D$$\n",
    "\n",
    "and then $p(D=0)=1-\\epsilon_D$. Say, $\\epsilon_D = 0.01$. \n",
    "\n",
    "Now assume that a person tested positive. What is the probability that this person has the disease? Is it 98% \n",
    "because $\\epsilon_{\\rm FP}=0.02$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We can't just read $p(D=1|T=1)$ off the table because the table entry is the conditional probability of the *test* given the *data*, $p(T=1|D=1)$. What we want is the conditional probability of the *data* given the *test*, that is, $p(D=1|T=1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bayes' rule then can be used to help us determine how likely it is that you have the disease if you tested positive:\n",
    "\n",
    "$$p(D=1|T=1) = \\frac{p(T=1|D=1)p(D=1)}{p(T=1)},$$\n",
    "\n",
    "where $$p(T=1) = p(T=1|D=0)p(D=0) + p(T=1|D=1)p(D=1).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Therefore:\n",
    "\n",
    "$$p(D=1|T=1) = \\frac{(1 - \\epsilon_{FN})\\epsilon_D}{\\epsilon_{FP}(1-\\epsilon_D) + (1-\\epsilon_{FN})\\epsilon_D} \\approx \\frac{\\epsilon_D}{\\epsilon_{FP}+\\epsilon_D}$$\n",
    "\n",
    "That means that to get a reliable diagnosis, we need $\\epsilon_{FP}$ to be quite small.  (Because you *want* the probability to be close to unity if you test positive, otherwise it is a *false* positive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In our example, we have a disease rate of 1% ($\\epsilon_D = 0.01$) and a false positive rate of 2% ($\\epsilon_{\\rm FP}=0.02$).  \n",
    "\n",
    "So we have:\n",
    "$$p(D=1|T=1) = \\frac{0.01}{0.02+0.01} = 0.333$$\n",
    "\n",
    "Then in a sample of, e.g.,  1000 people, 10 people test positive and *actually* have the disease $(1000*0.01)$, but another 20 $(1000*0.02)$ will test positive while healthy!\n",
    "\n",
    "Therefore, in that sample of 30 people who tested positive, only 1/3 has the disease (not 98%!). \n",
    "\n",
    "Same math, with often surprising results, applies to DNA tests of murder suspects... (more about this later in the course)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Descriptive statistics\n",
    "\n",
    "Typically, we collect some *samples* (series of measurements, or catalogs of stars) that can be thought of as being drawn from som underlying distribution (e.g., distribution of errors, or the distribution of stars in the Milky Way).\n",
    "\n",
    "We often don't care much about the individual samples, other than to use them ***to learn more about the underlying distributions and their properties (e.g., the mean (location), width (scale), etc.)***. How do we do that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SlideGrab](figures/p5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Normal probability density function (pdf): $$p(x|\\mu,\\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(\\frac{-(x-\\mu)^2}{2\\sigma^2}\\right).$$\n",
    "\n",
    "Cumulative distribution function (cdf): $$\\Phi(x|\\mu,\\sigma) = \\int_{-\\infty}^{x}  p(x'|\\mu,\\sigma) dx' $$\n",
    "$$\\Phi(\\infty|\\mu,\\sigma) = 1.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07fa2e4278>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Let's play with Gaussians! Or Normal distributions, N(mu,sigma)\n",
    "## see http://www.astroml.org/book_figures/chapter3/fig_gaussian_distribution.html\n",
    "## Example: IQ is (by definition) distributed as N(mu=100,sigma=15)\n",
    "## Let's plot the IQ distribution first\n",
    "# generate distribution for a grid of x values\n",
    "x = np.linspace(0, 200, 1000)\n",
    "mu=100\n",
    "sigma=15\n",
    "gauss = norm(mu, sigma).pdf(x)  # this is a function of x: gauss(x)\n",
    "# actual plotting\n",
    "fig, ax = plt.subplots(figsize=(5, 3.75))\n",
    "plt.plot(x, gauss, ls='-', c='black', label=r'$\\mu=%i,\\ \\sigma=%i$' % (mu, sigma))\n",
    "plt.xlim(0, 200)\n",
    "plt.ylim(0, 0.03)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel(r'$p(x|\\mu,\\sigma)$')\n",
    "plt.title('Gaussian Distribution')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00134989803163\n"
     ]
    }
   ],
   "source": [
    "## above we used probability density function (astronomers like to call it \"differential\" df)\n",
    "## the cumulative distribution function, cdf, is the integral of pdf from $x'=-\\infty$ to $x'=x$\n",
    "# What fraction of people have IQ>145?\n",
    "gaussCDF = norm(mu, sigma).cdf(145)\n",
    "print (1-gaussCDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nSigma= 4.75342430882\n",
      "IQ= 171.301364632\n"
     ]
    }
   ],
   "source": [
    "# What IQ corresponds to \"one in a million\"? \n",
    "nSigma = norm.ppf(1-1.0e-6)\n",
    "# norm.ppf returns x for specified cdf, assuming mu=0 and sigma=1 (\"standard normal pdf\")\n",
    "IQ = mu + nSigma*sigma\n",
    "print('nSigma=',nSigma)\n",
    "print('IQ=', IQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001399\n"
     ]
    }
   ],
   "source": [
    "# let's now look at the same problems using a sample of million points drawn from N(100,15)\n",
    "sampleSize=1000000 \n",
    "gaussSample = norm(mu, sigma).rvs(sampleSize) \n",
    "# What fraction of people have IQ>145?\n",
    "smartOnes = gaussSample[gaussSample>145]\n",
    "print (1.0*np.size(smartOnes)/sampleSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174.340605051\n"
     ]
    }
   ],
   "source": [
    "# What IQ corresponds to \"one in a million\"?  \n",
    "print(np.max(gaussSample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printStats(v):\n",
    "    print('Size:', np.size(v))\n",
    "    print('min:', np.min(v))\n",
    "    print('max:', np.max(v))\n",
    "    print('mean:', np.mean(v))\n",
    "    print('median:', np.median(v))\n",
    "    print('st.dev.:', np.std(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 1000000\n",
      "min: 23.5268646413\n",
      "max: 174.340605051\n",
      "mean: 100.008822975\n",
      "median: 100.010323528\n",
      "st.dev.: 15.008058373\n"
     ]
    }
   ],
   "source": [
    "printStats(gaussSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 1399\n",
      "min: 145.005570014\n",
      "max: 174.340605051\n",
      "mean: 149.226315866\n",
      "median: 148.132745381\n",
      "st.dev.: 3.95906136906\n"
     ]
    }
   ],
   "source": [
    "printStats(smartOnes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N(50 < IQ < 71):     26174\n",
      "N(26 < IQ < 51):     568\n"
     ]
    }
   ],
   "source": [
    "# What about the other end of the spectrum?\n",
    "print('N(50 < IQ < 71):    ', np.size(gaussSample[(gaussSample>50) & (gaussSample<71)]))\n",
    "print('N(26 < IQ < 51):    ', np.size(gaussSample[(gaussSample>26) & (gaussSample<51)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gaussian confidence levels\n",
    "\n",
    "The probability of a measurement drawn from a Gaussian distribution that is between $\\mu-a$ and $\\mu+b$ is\n",
    "$$\\int_{\\mu-a}^{\\mu+b} p(x|\\mu,\\sigma) dx.$$\n",
    "For $a=b=1\\sigma$, we get the familar result of 68.3%.  For $a=b=2\\sigma$ it is 95.4%.  So we refer to the range $\\mu \\pm 1\\sigma$ and $\\mu \\pm 2\\sigma$ as the 68% and 95% **confidence limits**, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## now let's go back to the problem of estimating location and scale\n",
    "## given a sample, such as gaussSample above, how do we estimate its mu and sigma?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SlideGrab](figures/p4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SlideGrab](figures/p3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sample vs. Population Statistics \n",
    "\n",
    "Statistics estimated from the *data* are called _sample statistics_ as compared to _population statistics_ which come from knowing the functional form of the pdf. For example, the expectation value for a known h(x) is\n",
    "\n",
    "$$\\mu \\equiv E(x) = \\int_{-\\infty}^{\\infty} x h(x) dx,$$\n",
    "\n",
    "where $h(x)$ must be properly normalized (the integral gets replaced by a sum for discrete distributions).\n",
    "\n",
    "E(x) is the expecation value of $x$.  If you want the expectation value of something else--say $x^2$ or $(x-\\mu)^2$, you replace $x$ with that. Importantly, the *variance* is the expectation value of $(x-\\mu)^2$\n",
    "\n",
    "$$\\sigma^2 \\equiv V = \\int_{-\\infty}^{\\infty}  (x-\\mu)^2 h(x) dx,$$\n",
    "\n",
    "where, again, the integral gets replaced by a sum for discrete distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Specifically, $\\mu$ is the *population average*, i.e., it is the expecation value of $x$ for $h(x)$.  But we don't *know* $h(x)$! So we do the next best thing, and estimate it from the data:\n",
    "\n",
    "$$ \\hat{h}(x) = \\sum_{i=1}^N \\frac{\\delta_(x - x_i)}{N}$$\n",
    "\n",
    "Plugging into the previous equations, we derive the **sample mean**, $\\overline{x}$ as an *estimator* of $\\mu$ and defined as\n",
    "$$\\overline{x} \\equiv \\frac{1}{N}\\sum_{i=1}^N x_i,$$\n",
    "which we determine from the data itself. We'll hear more about estimators in Week 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Similarly, the **sample variance** ($s^2$, where \n",
    "$s$ is the sample standard deviation) is an *estimator* of $\\sigma^2$:\n",
    "$$s^2 \\equiv \\frac{1}{N-1}\\sum_{i=1}^N (x_i-\\overline{x})^2.$$\n",
    "\n",
    "**WAIT!!!** Why do we have (N-1) and not N (as in expression for the mean)???\n",
    "\n",
    "The reason for the (N-1) term instead of the naively expected N in the second expression is related to the fact that $\\overline{x}$ is also determined from data (we will discuss this subtle fact and the underlying statistical justification for the (N-1) term in more detail in Week 4 lectures. With N replaced by (N-1) (the so-called Besselâ€™s correction), the sample variance (i.e., $\\sigma^2$) becomes unbiased (and the sample standard deviation becomes a less biased, but on average still underestimated, estimator of the true standard deviation). \n",
    "\n",
    "What does \"biased\" mean? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SlideGrab](figures/p13.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SlideGrab](figures/p10.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SlideGrab](figures/p11.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SlideGrab](figures/p12.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SlideGrab](figures/p8.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Anscombe's quartet comprises four datasets that have nearly identical simple descriptive statistics, yet appear very different when graphed. \n",
    "\n",
    "![SlideGrab](figures/AnscombeQuartet.jpg)\n",
    "\n",
    "![SlideGrab](figures/AnscombeQuartetTable.jpg)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "sky"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
